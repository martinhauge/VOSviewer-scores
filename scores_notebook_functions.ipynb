{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import required packages/dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "from reftypes import db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define user variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** REQUIRED ***\n",
    "# Set path pointing towards input file or folder.\n",
    "USER_INPUT = \"data/input/wos/innovation\"\n",
    "\n",
    "# Set name for output files without file extension.\n",
    "OUTPUT_NAME = \"notebook02\"\n",
    "\n",
    "# Set citation base key - default: Web of Science (see reftypes.py for options).\n",
    "BASE = 'wos'\n",
    "\n",
    "# Set scores value key - default: source (see reftypes.py for options).\n",
    "VAL = 'so'\n",
    "\n",
    "# *** OPTIONAL ***\n",
    "# Path for output - default: .\\data\\output\\\n",
    "OUTPUT_PATH = os.path.join('data', 'output')\n",
    "\n",
    "# If USER_INPUT is a folder ALL will include all files without asking.\n",
    "ALL = False\n",
    "\n",
    "# Skip creation of title/abstract file. Useful if several scores files are generated for the same input.\n",
    "SKIP = False\n",
    "\n",
    "# *** SETUP ***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input handling\n",
    "Check validity of input path and add files to analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input(USER_INPUT):\n",
    "    \n",
    "    # Check if USER_INPUT is a valid path\n",
    "    if not os.path.exists(USER_INPUT):\n",
    "        raise FileNotFoundError('Input path not found. Please check the USER_INPUT variable.')\n",
    "    \n",
    "    # Check if USER_INPUT is a folder or a file\n",
    "    if os.path.isdir(USER_INPUT):\n",
    "        \n",
    "        # Build list of file paths\n",
    "        files = [os.path.join(USER_INPUT, f) for f in os.listdir(USER_INPUT)]\n",
    "        \n",
    "        # Ask whether to include individual files - else include entire folder\n",
    "        if not ALL:\n",
    "            select_files = []\n",
    "            for f in files:\n",
    "                print('Add {} to analysis? (y/n)'.format(f))\n",
    "                response = input()\n",
    "                if response.lower() in ['y', 'yes']:\n",
    "                    select_files.append(f)\n",
    "                    print('{} added.'.format(f))\n",
    "                else:\n",
    "                    print('{} not added.'.format(f))\n",
    "                    continue\n",
    "            return select_files\n",
    "        else:\n",
    "            print('All files added to analysis.')\n",
    "            return files\n",
    "    else:\n",
    "        # Return path to file as single element list\n",
    "        return [USER_INPUT]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing\n",
    "Create pandas DataFrame object from input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(files):\n",
    "    # Setup database parameters from reftypes.py\n",
    "    separator = db[BASE]['sep']\n",
    "    code = db[BASE]['enc']\n",
    "    val = db[BASE][VAL]\n",
    "    title = db[BASE]['ti']\n",
    "    abstract = db[BASE]['ab']\n",
    "    quote = db[BASE]['quote']\n",
    "    \n",
    "    # Create empty DataFrame and append each file\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for f in files:\n",
    "        add_file = pd.read_csv(f, sep=separator, encoding=code, index_col=False, usecols=[title, abstract, val], quoting=quote)\n",
    "        df = df.append(add_file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter values and create list of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_df(df):\n",
    "    val = db[BASE][VAL]\n",
    "    \n",
    "    val_list = df[val].fillna('N/A')\n",
    "    val_list.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Create list of unique values\n",
    "    values = sorted(list(val_list.unique()))\n",
    "    values = set([str(i).lower() for i in values])\n",
    "    \n",
    "    # Create DataFrame with a binary table of scores\n",
    "    scores = pd.DataFrame(columns=values, index=val_list.index).fillna('0')\n",
    "    \n",
    "    # Populate each row of the binary table\n",
    "    for i, val in enumerate(val_list):\n",
    "        scores[str(val).lower()][i] = '1'\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up and prepare the column names for VOSviewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_header(scores):\n",
    "    \n",
    "    # Remove illegal characters from column names with regular expression:\n",
    "    scores.columns = [re.sub('[\\[\\]<>_]', '', col) for col in scores.columns]\n",
    "    \n",
    "    # Convert to VOSviewer scores header format:\n",
    "    scores.columns = ['score<{}>'.format(col) for col in scores.columns]\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File creation\n",
    "Export the scores DataFrame to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_file(scores):\n",
    "    \n",
    "    # Setup output values\n",
    "    val = db[BASE][VAL].replace(' ', '_')\n",
    "    sep_val = '\\t'\n",
    "    output_path = os.path.join(OUTPUT_PATH, OUTPUT_NAME)\n",
    "    output_name = '{}_{}_scores.txt'.format(output_path, val)\n",
    "    if os.path.exists(output_name):\n",
    "        raise Exception('File already exists. Change OUTPUT_NAME and try again.')\n",
    "    scores.to_csv(path_or_buf=output_name, sep=sep_val, index=False)\n",
    "    \n",
    "    return 'Scores file created.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate text file with title and abstract for each citation (corpus file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_file(df):\n",
    "    \n",
    "    # Setup output values\n",
    "    sep_val = '\\t'\n",
    "    output_path = os.path.join(OUTPUT_PATH, OUTPUT_NAME)\n",
    "    output_name = '{}_corpus.txt'.format(output_path)\n",
    "    df[db[BASE]['ab']] = df[db[BASE]['ab']].fillna('-')\n",
    "    corpus = pd.DataFrame(df[db[BASE]['ti']] + ' ' + df[db[BASE]['ab']])\n",
    "    if os.path.exists(output_name):\n",
    "        raise Exception('File already exists. Change OUTPUT_NAME and try again.\\nNote: corpus files can be re-used with different scores files from the same data set.')\n",
    "    corpus.to_csv(path_or_buf=output_name, sep=sep_val, index=False, header=False)\n",
    "    \n",
    "    return 'Corpus file created.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution\n",
    "Generate and format the DataFrames from the data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df(get_input(USER_INPUT))\n",
    "\n",
    "scores = format_header(scores_df(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the scores file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_file(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the corpus file with titles and abstracts for each citation.\n",
    "\n",
    "Note: the same corpus file can be used with different scores files from the same data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_file(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corpus and scores files can be loaded into VOSviewer by creating a map based on text data and reading data from VOSviewer files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
